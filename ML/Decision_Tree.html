<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>

<style type='text/css'>html {overflow-x: initial !important;}:root { --bg-color:#ffffff; --text-color:#333333; --select-text-bg-color:#B5D6FC; --select-text-font-color:auto; --monospace:"Lucida Console",Consolas,"Courier",monospace; --title-bar-height:20px; }
.mac-os-11 { --title-bar-height:28px; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
h1, h2, h3, h4, h5 { white-space: pre-wrap; }
body { margin: 0px; padding: 0px; height: auto; inset: 0px; font-size: 1rem; line-height: 1.42857; overflow-x: hidden; background: inherit; tab-size: 4; }
iframe { margin: auto; }
a.url { word-break: break-all; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { text-shadow: none; background: var(--select-text-bg-color); color: var(--select-text-font-color); }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; overflow-wrap: break-word; position: relative; white-space: normal; overflow-x: visible; padding-top: 36px; }
#write.first-line-indent p { text-indent: 2em; }
#write.first-line-indent li p, #write.first-line-indent p * { text-indent: 0px; }
#write.first-line-indent li { margin-left: 2em; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
.typora-export .footnote-line, .typora-export li, .typora-export p { white-space: pre-wrap; }
.typora-export .task-list-item input { pointer-events: none; }
@media screen and (max-width: 500px) {
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  #write { padding-left: 20px; padding-right: 20px; }
}
#write li > figure:last-child { margin-bottom: 0.5rem; }
#write ol, #write ul { position: relative; }
img { max-width: 100%; vertical-align: middle; image-orientation: from-image; }
button, input, select, textarea { color: inherit; font: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
*, ::after, ::before { box-sizing: border-box; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p { position: relative; }
p { line-height: inherit; }
h1, h2, h3, h4, h5, h6 { break-after: avoid-page; break-inside: avoid; orphans: 4; }
p { orphans: 4; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
.md-math-block, .md-rawblock, h1, h2, h3, h4, h5, h6, p { margin-top: 1rem; margin-bottom: 1rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.7); color: rgb(85, 85, 85); border-radius: 4px; cursor: pointer; }
sup.md-footnote a, sup.md-footnote a:hover { color: inherit; text-transform: inherit; text-decoration: inherit; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; }
figure { overflow-x: auto; margin: 1.2em 0px; max-width: calc(100% + 16px); padding: 0px; }
figure > table { margin: 0px; }
thead, tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 32px; }
.CodeMirror-gutters { border-right: 0px; background-color: inherit; }
.CodeMirror-linenumber { user-select: none; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
#write pre { white-space: pre-wrap; }
#write.fences-no-line-wrapping pre { white-space: pre; }
#write pre.ty-contain-cm { white-space: normal; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background: inherit; position: relative !important; }
.md-fences-adv-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
#write .md-fences.mock-cm { white-space: pre-wrap; }
.md-fences.md-fences-with-lineno { padding-left: 0px; }
#write.fences-no-line-wrapping .md-fences.mock-cm { white-space: pre; overflow-x: auto; }
.md-fences.mock-cm.md-fences-with-lineno { padding-left: 8px; }
.CodeMirror-line, twitterwidget { break-inside: avoid; }
svg { break-inside: avoid; }
.footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; }
.footnotes + .footnotes { margin-top: 0px; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; background: 0px 0px; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; -webkit-tap-highlight-color: transparent; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; direction: ltr; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li .mathjax-block, li p { margin: 0.5rem 0px; }
li blockquote { margin: 1rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child, li > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: normal; }
#write .footnote-line { white-space: pre-wrap; }
@media print {
  body, html { border: 1px solid transparent; height: 99%; break-after: avoid; break-before: avoid; font-variant-ligatures: no-common-ligatures; }
  #write { margin-top: 0px; border-color: transparent !important; padding-top: 0px !important; padding-bottom: 0px !important; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  .typora-export #write { break-after: avoid; }
  .typora-export #write::after { height: 0px; }
  .is-mac table { break-inside: avoid; }
  #write > p:nth-child(1) { margin-top: 0px; }
  .typora-export-show-outline .typora-export-sidebar { display: none; }
  figure { overflow-x: visible; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background: rgb(204, 204, 204); display: block; overflow-x: hidden; }
p > .md-image:only-child:not(.md-img-error) img, p > img:only-child { display: block; margin: auto; }
#write.first-line-indent p > .md-image:only-child:not(.md-img-error) img { left: -2em; position: relative; }
p > .md-image:only-child { display: inline-block; width: 100%; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.md-math-block { width: 100%; }
.md-math-block:not(:empty)::after { display: none; }
.MathJax_ref { fill: currentcolor; }
[contenteditable="true"]:active, [contenteditable="true"]:focus, [contenteditable="false"]:active, [contenteditable="false"]:focus { outline: 0px; box-shadow: none; }
.md-task-list-item { position: relative; list-style-type: none; }
.task-list-item.md-task-list-item { padding-left: 0px; }
.md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); border: none; }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc-content::after, .md-toc::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-item a { text-decoration: none; }
.md-toc-inner:hover { text-decoration: underline; }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) {
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.reversefootnote { font-family: ui-monospace, sans-serif; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
code, pre, samp, tt { font-family: var(--monospace); }
kbd { margin: 0px 0.1em; padding: 0.1em 0.6em; font-size: 0.8em; color: rgb(36, 39, 41); background: rgb(255, 255, 255); border: 1px solid rgb(173, 179, 185); border-radius: 3px; box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px, rgb(255, 255, 255) 0px 0px 0px 2px inset; white-space: nowrap; vertical-align: middle; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.6; font-family: var(--monospace); }
code { text-align: left; vertical-align: initial; }
a.md-print-anchor { white-space: pre !important; border-width: initial !important; border-style: none !important; border-color: initial !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; background: 0px 0px !important; text-decoration: initial !important; text-shadow: initial !important; }
.os-windows.monocolor-emoji .md-emoji { font-family: "Segoe UI Symbol", sans-serif; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="flow"] svg, [lang="mermaid"] svg { max-width: 100%; height: auto; }
[lang="mermaid"] .node text { font-size: 1rem; }
table tr th { border-bottom: 0px; }
video { max-width: 100%; display: block; margin: 0px auto; }
iframe { max-width: 100%; width: 100%; border: none; }
.highlight td, .highlight tr { border: 0px; }
mark { background: rgb(255, 255, 0); color: rgb(0, 0, 0); }
.md-html-inline .md-plain, .md-html-inline strong, mark .md-inline-math, mark strong { color: inherit; }
.md-expand mark .md-meta { opacity: 0.3 !important; }
mark .md-meta { color: rgb(0, 0, 0); }
@media print {
  .typora-export h1, .typora-export h2, .typora-export h3, .typora-export h4, .typora-export h5, .typora-export h6 { break-inside: avoid; }
}
.md-diagram-panel .messageText { stroke: none !important; }
.md-diagram-panel .start-state { fill: var(--node-fill); }
.md-diagram-panel .edgeLabel rect { opacity: 1 !important; }
.md-fences.md-fences-math { font-size: 1em; }
.md-fences-advanced:not(.md-focus) { padding: 0px; white-space: nowrap; border: 0px; }
.md-fences-advanced:not(.md-focus) { background: inherit; }
.typora-export-show-outline .typora-export-content { max-width: 1440px; margin: auto; display: flex; flex-direction: row; }
.typora-export-sidebar { width: 300px; font-size: 0.8rem; margin-top: 80px; margin-right: 18px; }
.typora-export-show-outline #write { --webkit-flex:2; flex: 2 1 0%; }
.typora-export-sidebar .outline-content { position: fixed; top: 0px; max-height: 100%; overflow: hidden auto; padding-bottom: 30px; padding-top: 60px; width: 300px; }
@media screen and (max-width: 1024px) {
  .typora-export-sidebar, .typora-export-sidebar .outline-content { width: 240px; }
}
@media screen and (max-width: 800px) {
  .typora-export-sidebar { display: none; }
}
.outline-content li, .outline-content ul { margin-left: 0px; margin-right: 0px; padding-left: 0px; padding-right: 0px; list-style: none; overflow-wrap: anywhere; }
.outline-content ul { margin-top: 0px; margin-bottom: 0px; }
.outline-content strong { font-weight: 400; }
.outline-expander { width: 1rem; height: 1.42857rem; position: relative; display: table-cell; vertical-align: middle; cursor: pointer; padding-left: 4px; }
.outline-expander::before { content: ""; position: relative; font-family: Ionicons; display: inline-block; font-size: 8px; vertical-align: middle; }
.outline-item { padding-top: 3px; padding-bottom: 3px; cursor: pointer; }
.outline-expander:hover::before { content: ""; }
.outline-h1 > .outline-item { padding-left: 0px; }
.outline-h2 > .outline-item { padding-left: 1em; }
.outline-h3 > .outline-item { padding-left: 2em; }
.outline-h4 > .outline-item { padding-left: 3em; }
.outline-h5 > .outline-item { padding-left: 4em; }
.outline-h6 > .outline-item { padding-left: 5em; }
.outline-label { cursor: pointer; display: table-cell; vertical-align: middle; text-decoration: none; color: inherit; }
.outline-label:hover { text-decoration: underline; }
.outline-item:hover { border-color: rgb(245, 245, 245); background-color: var(--item-hover-bg-color); }
.outline-item:hover { margin-left: -28px; margin-right: -28px; border-left: 28px solid transparent; border-right: 28px solid transparent; }
.outline-item-single .outline-expander::before, .outline-item-single .outline-expander:hover::before { display: none; }
.outline-item-open > .outline-item > .outline-expander::before { content: ""; }
.outline-children { display: none; }
.info-panel-tab-wrapper { display: none; }
.outline-item-open > .outline-children { display: block; }
.typora-export .outline-item { padding-top: 1px; padding-bottom: 1px; }
.typora-export .outline-item:hover { margin-right: -8px; border-right: 8px solid transparent; }
.typora-export .outline-expander::before { content: "+"; font-family: inherit; top: -1px; }
.typora-export .outline-expander:hover::before, .typora-export .outline-item-open > .outline-item > .outline-expander::before { content: "−"; }
.typora-export-collapse-outline .outline-children { display: none; }
.typora-export-collapse-outline .outline-item-open > .outline-children, .typora-export-no-collapse-outline .outline-children { display: block; }
.typora-export-no-collapse-outline .outline-expander::before { content: "" !important; }
.typora-export-show-outline .outline-item-active > .outline-item .outline-label { font-weight: 700; }
.md-inline-math-container mjx-container { zoom: 0.95; }
mjx-container { break-inside: avoid; }


.CodeMirror { height: auto; }
.CodeMirror.cm-s-inner { background: inherit; }
.CodeMirror-scroll { overflow: auto hidden; z-index: 3; }
.CodeMirror-gutter-filler, .CodeMirror-scrollbar-filler { background-color: rgb(255, 255, 255); }
.CodeMirror-gutters { border-right: 1px solid rgb(221, 221, 221); background: inherit; white-space: nowrap; }
.CodeMirror-linenumber { padding: 0px 3px 0px 5px; text-align: right; color: rgb(153, 153, 153); }
.cm-s-inner .cm-keyword { color: rgb(119, 0, 136); }
.cm-s-inner .cm-atom, .cm-s-inner.cm-atom { color: rgb(34, 17, 153); }
.cm-s-inner .cm-number { color: rgb(17, 102, 68); }
.cm-s-inner .cm-def { color: rgb(0, 0, 255); }
.cm-s-inner .cm-variable { color: rgb(0, 0, 0); }
.cm-s-inner .cm-variable-2 { color: rgb(0, 85, 170); }
.cm-s-inner .cm-variable-3 { color: rgb(0, 136, 85); }
.cm-s-inner .cm-string { color: rgb(170, 17, 17); }
.cm-s-inner .cm-property { color: rgb(0, 0, 0); }
.cm-s-inner .cm-operator { color: rgb(152, 26, 26); }
.cm-s-inner .cm-comment, .cm-s-inner.cm-comment { color: rgb(170, 85, 0); }
.cm-s-inner .cm-string-2 { color: rgb(255, 85, 0); }
.cm-s-inner .cm-meta { color: rgb(85, 85, 85); }
.cm-s-inner .cm-qualifier { color: rgb(85, 85, 85); }
.cm-s-inner .cm-builtin { color: rgb(51, 0, 170); }
.cm-s-inner .cm-bracket { color: rgb(153, 153, 119); }
.cm-s-inner .cm-tag { color: rgb(17, 119, 0); }
.cm-s-inner .cm-attribute { color: rgb(0, 0, 204); }
.cm-s-inner .cm-header, .cm-s-inner.cm-header { color: rgb(0, 0, 255); }
.cm-s-inner .cm-quote, .cm-s-inner.cm-quote { color: rgb(0, 153, 0); }
.cm-s-inner .cm-hr, .cm-s-inner.cm-hr { color: rgb(153, 153, 153); }
.cm-s-inner .cm-link, .cm-s-inner.cm-link { color: rgb(0, 0, 204); }
.cm-negative { color: rgb(221, 68, 68); }
.cm-positive { color: rgb(34, 153, 34); }
.cm-header, .cm-strong { font-weight: 700; }
.cm-del { text-decoration: line-through; }
.cm-em { font-style: italic; }
.cm-link { text-decoration: underline; }
.cm-error { color: red; }
.cm-invalidchar { color: red; }
.cm-constant { color: rgb(38, 139, 210); }
.cm-defined { color: rgb(181, 137, 0); }
div.CodeMirror span.CodeMirror-matchingbracket { color: rgb(0, 255, 0); }
div.CodeMirror span.CodeMirror-nonmatchingbracket { color: rgb(255, 34, 34); }
.cm-s-inner .CodeMirror-activeline-background { background: inherit; }
.CodeMirror { position: relative; overflow: hidden; }
.CodeMirror-scroll { height: 100%; outline: 0px; position: relative; box-sizing: content-box; background: inherit; }
.CodeMirror-sizer { position: relative; }
.CodeMirror-gutter-filler, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-vscrollbar { position: absolute; z-index: 6; display: none; outline: 0px; }
.CodeMirror-vscrollbar { right: 0px; top: 0px; overflow: hidden; }
.CodeMirror-hscrollbar { bottom: 0px; left: 0px; overflow: auto hidden; }
.CodeMirror-scrollbar-filler { right: 0px; bottom: 0px; }
.CodeMirror-gutter-filler { left: 0px; bottom: 0px; }
.CodeMirror-gutters { position: absolute; left: 0px; top: 0px; padding-bottom: 10px; z-index: 3; overflow-y: hidden; }
.CodeMirror-gutter { white-space: normal; height: 100%; box-sizing: content-box; padding-bottom: 30px; margin-bottom: -32px; display: inline-block; }
.CodeMirror-gutter-wrapper { position: absolute; z-index: 4; background: 0px 0px !important; border: none !important; }
.CodeMirror-gutter-background { position: absolute; top: 0px; bottom: 0px; z-index: 4; }
.CodeMirror-gutter-elt { position: absolute; cursor: default; z-index: 4; }
.CodeMirror-lines { cursor: text; }
.CodeMirror pre { border-radius: 0px; border-width: 0px; background: 0px 0px; font-family: inherit; font-size: inherit; margin: 0px; white-space: pre; overflow-wrap: normal; color: inherit; z-index: 2; position: relative; overflow: visible; }
.CodeMirror-wrap pre { overflow-wrap: break-word; white-space: pre-wrap; word-break: normal; }
.CodeMirror-code pre { border-right: 30px solid transparent; width: fit-content; }
.CodeMirror-wrap .CodeMirror-code pre { border-right: none; width: auto; }
.CodeMirror-linebackground { position: absolute; inset: 0px; z-index: 0; }
.CodeMirror-linewidget { position: relative; z-index: 2; overflow: auto; }
.CodeMirror-wrap .CodeMirror-scroll { overflow-x: hidden; }
.CodeMirror-measure { position: absolute; width: 100%; height: 0px; overflow: hidden; visibility: hidden; }
.CodeMirror-measure pre { position: static; }
.CodeMirror div.CodeMirror-cursor { position: absolute; visibility: hidden; border-right: none; width: 0px; }
.CodeMirror div.CodeMirror-cursor { visibility: hidden; }
.CodeMirror-focused div.CodeMirror-cursor { visibility: inherit; }
.cm-searching { background: rgba(255, 255, 0, 0.4); }
span.cm-underlined { text-decoration: underline; }
span.cm-strikethrough { text-decoration: line-through; }
.cm-tw-syntaxerror { color: rgb(255, 255, 255); background-color: rgb(153, 0, 0); }
.cm-tw-deleted { text-decoration: line-through; }
.cm-tw-header5 { font-weight: 700; }
.cm-tw-listitem:first-child { padding-left: 10px; }
.cm-tw-box { border-style: solid; border-right-width: 1px; border-bottom-width: 1px; border-left-width: 1px; border-color: inherit; border-top-width: 0px !important; }
.cm-tw-underline { text-decoration: underline; }
@media print {
  .CodeMirror div.CodeMirror-cursor { visibility: hidden; }
}


html {
	font-size: 19px;
}

html, body {
	margin: auto;
	background: #fefefe;
	-webkit-font-smoothing: antialiased;
}
body {
	font-family: "Vollkorn", Palatino, Times;
	color: #333;
	line-height: 1.4;
	text-align: justify;
}

#write {
	max-width: 960px;
	margin: 0 auto;
	margin-bottom: 2em;
	line-height: 1.53;
	padding-top: 40px;
}

@media only screen and (min-width: 1400px) {
	#write {
		max-width: 1100px;
	}
}

@media print {
	html {
		font-size: 13px;
	}
}

/* Typography
-------------------------------------------------------- */

#write>h1:first-child,
h1 {
	margin-top: 1.6em;
	font-weight: normal;
}

h1 {
	font-size:3em;
}

h2 {
	margin-top:2em;
	font-weight: normal;
}

h3 {
	font-weight: normal;
	font-style: italic;
	margin-top: 3em;
}

h1, 
h2, 
h3{
	text-align: center;
}

h2:after{
	border-bottom: 1px solid #2f2f2f;
    content: '';
    width: 100px;
    display: block;
    margin: 0 auto;
    height: 1px;
}

h1+h2, h2+h3 {
	margin-top: 0.83em;
}

p,
.mathjax-block {
	margin-top: 0;
	-webkit-hypens: auto;
	-moz-hypens: auto;
	hyphens: auto;
}
ul {
	list-style: square;
	padding-left: 1.2em;
}
ol {
	padding-left: 1.2em;
}
blockquote {
	margin-left: 1em;
	padding-left: 1em;
	border-left: 1px solid #ddd;
}
code,
pre {
	font-family: "Consolas", "Menlo", "Monaco", monospace, serif;
	font-size: .9em;
	background: white;
}
.md-fences{
	margin-left: 1em;
	padding-left: 1em;
	border: 1px solid #ddd;
	padding-bottom: 8px;
	padding-top: 6px;
	margin-bottom: 1.5em;
}

a {
	color: #2484c1;
	text-decoration: none;
}
a:hover {
	text-decoration: underline;
}
a img {
	border: none;
}
h1 a,
h1 a:hover {
	color: #333;
	text-decoration: none;
}
hr {
	color: #ddd;
	height: 1px;
	margin: 2em 0;
	border-top: solid 1px #ddd;
	border-bottom: none;
	border-left: 0;
	border-right: 0;
}
.ty-table-edit {
	background: #ededed;
    padding-top: 4px;
}
table {
	margin-bottom: 1.333333rem
}
table th,
table td {
	padding: 8px;
	line-height: 1.333333rem;
	vertical-align: top;
	border-top: 1px solid #ddd
}
table th {
	font-weight: bold
}
table thead th {
	vertical-align: bottom
}
table caption+thead tr:first-child th,
table caption+thead tr:first-child td,
table colgroup+thead tr:first-child th,
table colgroup+thead tr:first-child td,
table thead:first-child tr:first-child th,
table thead:first-child tr:first-child td {
	border-top: 0
}
table tbody+tbody {
	border-top: 2px solid #ddd
}

.task-list{
	padding:0;
}

.md-task-list-item {
	padding-left: 1.6rem;
}

.md-task-list-item > input:before {
	content: '\221A';
	display: inline-block;
	width: 1.33333333rem;
  	height: 1.6rem;
	vertical-align: middle;
	text-align: center;
	color: #ddd;
	background-color: #fefefe;
}

.md-task-list-item > input:checked:before,
.md-task-list-item > input[checked]:before{
	color: inherit;
}
.md-tag {
	color: inherit;
	font: inherit;
}
#write pre.md-meta-block {
	min-height: 35px;
	padding: 0.5em 1em;
}
#write pre.md-meta-block {
	white-space: pre;
	background: #f8f8f8;
	border: 0px;
	color: #999;
	
	width: 100vw;
	max-width: calc(100% + 60px);
	margin-left: -30px;
	border-left: 30px #f8f8f8 solid;
	border-right: 30px #f8f8f8 solid;

	margin-bottom: 2em;
	margin-top: -1.3333333333333rem;
	padding-top: 26px;
	padding-bottom: 10px;
	line-height: 1.8em;
	font-size: 0.9em;
	font-size: 0.76em;
	padding-left: 0;
}
.md-img-error.md-image>.md-meta{
	vertical-align: bottom;
}
#write>h5.md-focus:before {
	top: 2px;
}

.md-toc {
	margin-top: 40px;
}

.md-toc-content {
	padding-bottom: 20px;
}

.outline-expander:before {
	color: inherit;
	font-size: 14px;
	top: auto;
	content: "\f0da";
	font-family: FontAwesome;
}

.outline-expander:hover:before,
.outline-item-open>.outline-item>.outline-expander:before {
  	content: "\f0d7";
}

/** source code mode */
#typora-source {
	font-family: Courier, monospace;
    color: #6A6A6A;
}

.html-for-mac #typora-sidebar {
    -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, .175);
    box-shadow: 0 6px 12px rgba(0, 0, 0, .175);
}

.cm-s-typora-default .cm-header, 
.cm-s-typora-default .cm-property,
.CodeMirror.cm-s-typora-default div.CodeMirror-cursor {
	color: #428bca;
}

.cm-s-typora-default .cm-atom, .cm-s-typora-default .cm-number {
	color: #777777;
}

.typora-node .file-list-item-parent-loc, 
.typora-node .file-list-item-time, 
.typora-node .file-list-item-summary {
	font-family: arial, sans-serif;
}

.md-task-list-item>input {
    margin-left: -1.3em;
    margin-top: calc(1rem - 12px);
}

.md-mathjax-midline {
	background: #fafafa;
}

.md-fences .code-tooltip {
	bottom: -2em !important;
}

.dropdown-menu .divider {
	border-color: #e5e5e5;
}


</style><title>Decision Tree</title>
</head>
<body class='typora-export os-windows'><div class='typora-export-content'>
<div id='write'  class=''><h2 id='decision-tree'><span>Decision Tree</span></h2><p><img src="https://storage.googleapis.com/algodailyrandomassets/curriculum/Data_Science/Getting%20to%20Know%20Decision%20Trees/decision_tree.png" alt="AlgoDaily - Getting to Know Decision Trees - Introduction" style="zoom:50%;" /></p><div class='md-toc' mdtype='toc'><p class="md-toc-content" role="list"><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n0"><a class="md-toc-inner" href="#decision-tree">Decision Tree</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n2"><a class="md-toc-inner" href="#key-takeaways">Key takeaways</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n48"><a class="md-toc-inner" href="#interview-questions">Interview Questions</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n95"><a class="md-toc-inner" href="#solutions">Solutions</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n100"><a class="md-toc-inner" href="#what-is-a-decision-tree-and-how-does-it-work">What is a Decision Tree, and how does it work?</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n103"><a class="md-toc-inner" href="#what-are-the-advantages-of-using-decision-trees-for-classification-or-regression-tasks">What are the advantages of using Decision Trees for classification or regression tasks?</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n119"><a class="md-toc-inner" href="#what-are-the-different-splitting-criteria-used-in-decision-trees-and-how-do-they-affect-the-trees-construction">What are the different splitting criteria used in Decision Trees, and how do they affect the tree's construction?</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n129"><a class="md-toc-inner" href="#how-do-you-handle-missing-values-in-a-dataset-when-building-a-decision-tree">How do you handle missing values in a dataset when building a Decision Tree?</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n140"><a class="md-toc-inner" href="#what-is-overfitting-in-the-context-of-decision-trees-and-how-can-it-be-addressed">What is overfitting in the context of Decision Trees, and how can it be addressed?</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n154"><a class="md-toc-inner" href="#what-is-pruning-and-why-is-it-important-in-decision-trees">What is pruning, and why is it important in Decision Trees?</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n159"><a class="md-toc-inner" href="#what-are-the-different-measures-used-to-assess-the-quality-of-splits-in-decision-trees">What are the different measures used to assess the quality of splits in Decision Trees?</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n169"><a class="md-toc-inner" href="#how-do-you-handle-categorical-variables-in-a-decision-tree-algorithm">How do you handle categorical variables in a Decision Tree algorithm?</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n177"><a class="md-toc-inner" href="#how-can-you-handle-continuous-or-numerical-variables-in-decision-trees">How can you handle continuous or numerical variables in Decision Trees?</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n190"><a class="md-toc-inner" href="#what-are-some-methods-for-dealing-with-imbalanced-datasets-when-using-decision-trees">What are some methods for dealing with imbalanced datasets when using Decision Trees?</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n204"><a class="md-toc-inner" href="#can-you-explain-the-concept-of-feature-importance-in-decision-trees">Can you explain the concept of feature importance in Decision Trees?</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n211"><a class="md-toc-inner" href="#what-are-ensemble-methods-and-how-can-they-be-combined-with-decision-trees">What are ensemble methods, and how can they be combined with Decision Trees?</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n221"><a class="md-toc-inner" href="#what-is-the-difference-between-random-forests-and-gradient-boosting-algorithms">What is the difference between Random Forests and Gradient Boosting algorithms?</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n237"><a class="md-toc-inner" href="#how-do-you-determine-the-optimal-depth-or-size-of-a-decision-tree">How do you determine the optimal depth or size of a Decision Tree?</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n249"><a class="md-toc-inner" href="#can-you-explain-the-concept-of-information-gain-or-impurity-reduction-in-decision-trees">Can you explain the concept of information gain or impurity reduction in Decision Trees?</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n256"><a class="md-toc-inner" href="#how-do-you-evaluate-the-performance-of-a-decision-tree-model">How do you evaluate the performance of a Decision Tree model?</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n282"><a class="md-toc-inner" href="#can-decision-trees-handle-multi-class-classification-problems">Can Decision Trees handle multi-class classification problems?</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n285"><a class="md-toc-inner" href="#how-do-you-interpret-the-rules-generated-by-a-decision-tree-model">How do you interpret the rules generated by a Decision Tree model?</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n289"><a class="md-toc-inner" href="#can-decision-trees-handle-missing-values-and-outliers-during-the-prediction-phase">Can Decision Trees handle missing values and outliers during the prediction phase?</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n293"><a class="md-toc-inner" href="#how-can-decision-trees-be-used-for-feature-selection-or-variable-importance-ranking">How can Decision Trees be used for feature selection or variable importance ranking?</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n306"><a class="md-toc-inner" href="#python-application">Python Application</a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n308"><a class="md-toc-inner" href="#using-sklearn">Using Sklearn</a></span><span role="listitem" class="md-toc-item md-toc-h5" data-ref="n317"><a class="md-toc-inner" href="#decisiontreeclassifier"><code>DecisionTreeClassifier() </code></a></span><span role="listitem" class="md-toc-item md-toc-h4" data-ref="n356"><a class="md-toc-inner" href="#from-scratch">From Scratch</a></span></p></div><p>&nbsp;</p><h3 id='key-takeaways'><span>Key takeaways</span></h3><ol><li><p><span>Feature selection: Choose the most relevant and informative features to build the decision tree. Consider features that have a strong relationship with the target variable.</span></p></li><li><p><span>Splitting criteria: Select an appropriate splitting criterion (e.g., Gini index, entropy) to determine how to divide the data at each node of the tree.</span></p></li><li><p><span>Handling missing values: Decide how to handle missing values in the dataset, whether by imputation or using specific techniques designed for decision trees.</span></p></li><li><p><span>Pruning: Consider pruning techniques, such as cost complexity pruning or reduced error pruning, to prevent overfitting and improve the generalization ability of the decision tree.</span></p></li><li><p><span>Handling categorical variables: Determine how to handle categorical variables in the decision tree algorithm, such as one-hot encoding or label encoding.</span></p></li><li><p><span>Tree depth and complexity: Control the depth and complexity of the decision tree to avoid overfitting. Setting maximum depth or minimum number of samples per leaf can help regulate tree growth.</span></p></li><li><p><span>Interpretability: Leverage the interpretability of decision trees to gain insights into the decision-making process. Decision trees provide transparent and easily understandable rules for classification or regression.</span></p></li><li><p><span>Ensemble methods: Consider using ensemble methods, such as Random Forests or Gradient Boosting, which combine multiple decision trees to improve prediction accuracy and robustness.</span></p></li><li><p><span>Feature importance: Analyze the feature importance provided by the decision tree to identify the most influential features in the classification or regression task.</span></p></li><li><p><span>Regularization and parameter tuning: Explore regularization techniques, such as reducing the maximum number of features or adjusting other hyperparameters, to optimize the performance of the decision tree.</span></p></li></ol><h3 id='interview-questions'><span>Interview Questions</span></h3><ol><li><p><span>What is a Decision Tree, and how does it work?</span></p></li><li><p><span>What are the advantages of using Decision Trees for classification or regression tasks?</span></p></li><li><p><span>What are the different splitting criteria used in Decision Trees, and how do they affect the tree&#39;s construction?</span></p></li><li><p><span>How do you handle missing values in a dataset when building a Decision Tree?</span></p></li><li><p><span>What is overfitting in the context of Decision Trees, and how can it be addressed?</span></p></li><li><p><span>What is pruning, and why is it important in Decision Trees?</span></p></li><li><p><span>What are the different measures used to assess the quality of splits in Decision Trees?</span></p></li><li><p><span>How do you handle categorical variables in a Decision Tree algorithm?</span></p></li><li><p><span>How can you handle continuous or numerical variables in Decision Trees?</span></p></li><li><p><span>What are some methods for dealing with imbalanced datasets when using Decision Trees?</span></p></li><li><p><span>Can you explain the concept of feature importance in Decision Trees?</span></p></li><li><p><span>What are ensemble methods, and how can they be combined with Decision Trees?</span></p></li><li><p><span>What is the difference between Random Forests and Gradient Boosting algorithms?</span></p></li><li><p><span>How do you determine the optimal depth or size of a Decision Tree?</span></p></li><li><p><span>Can you explain the concept of information gain or impurity reduction in Decision Trees?</span></p></li><li><p><span>How do you evaluate the performance of a Decision Tree model?</span></p></li><li><p><span>Can Decision Trees handle multi-class classification problems?</span></p></li><li><p><span>How do you interpret the rules generated by a Decision Tree model?</span></p></li><li><p><span>Can Decision Trees handle missing values and outliers during the prediction phase?</span></p></li><li><p><span>How can Decision Trees be used for feature selection or variable importance ranking?</span></p></li></ol><h3 id='solutions'><span>Solutions</span></h3><h4 id='what-is-a-decision-tree-and-how-does-it-work'><span>What is a Decision Tree, and how does it work?</span></h4><p><span>A Decision Tree is a </span><strong><span>supervised machine learning algorithm</span></strong><span> that can be used for classification and regression tasks. It takes a dataset as input and recursively partitions the data based on the values of input features to create a tree-like model. The tree structure consists of internal nodes representing features, branches representing decisions based on feature values, and leaf nodes representing the predicted output or class labels.</span></p><p><span>The construction of a Decision Tree involves selecting the best features to </span><strong><span>split the data at each internal node based on certain criteria, such as information gain or Gini impurity</span></strong><span>. The goal is to create a tree that maximizes the separation of classes or minimizes the variance within each class.</span></p><h4 id='what-are-the-advantages-of-using-decision-trees-for-classification-or-regression-tasks'><span>What are the advantages of using Decision Trees for classification or regression tasks?</span></h4><ul><li><p><span>Decision Trees are easy to understand and interpret. The generated rules can be visualized and easily explained to stakeholders.</span></p></li><li><p><span>They can handle both categorical and numerical data without requiring extensive data preprocessing.</span></p></li><li><p><span>Decision Trees can handle nonlinear relationships between features and the target variable.</span></p></li><li><p><span>They can handle missing values by effectively utilizing available information for decision-making.</span></p></li><li><p><span>Decision Trees are robust to outliers and can still provide accurate predictions.</span></p></li><li><p><span>They can handle multi-class classification problems.</span></p></li><li><p><span>Decision Trees can be combined with ensemble methods to improve performance.</span></p></li></ul><h4 id='what-are-the-different-splitting-criteria-used-in-decision-trees-and-how-do-they-affect-the-trees-construction'><span>What are the different splitting criteria used in Decision Trees, and how do they affect the tree&#39;s construction?</span></h4><p><span>The commonly used splitting criteria in Decision Trees include:</span></p><ol><li><p><span>Gini impurity: It measures the degree of impurity or the probability of incorrectly classifying a randomly chosen element in a dataset.</span></p></li><li><p><span>Information gain: It calculates the reduction in entropy (uncertainty) achieved by splitting the data based on a particular feature.</span></p></li><li><p><span>Gain ratio: It is similar to information gain but takes into account the intrinsic information of each feature.</span></p></li></ol><p><span>These splitting criteria affect the construction of the tree by determining the order and quality of feature selection for splitting. The criterion with the highest value is chosen at each internal node to maximize the purity or information gain in the resulting subsets.</span></p><h4 id='how-do-you-handle-missing-values-in-a-dataset-when-building-a-decision-tree'><span>How do you handle missing values in a dataset when building a Decision Tree?</span></h4><p><span>When handling missing values in a dataset for a Decision Tree:</span></p><ol><li><p><span>Missing values can be treated as a separate category if the feature is categorical.</span></p></li><li><p><span>For numerical features, missing values can be replaced with the mean, median, or another appropriate measure.</span></p></li><li><p><span>Missing values can be imputed based on other correlated features or using advanced imputation techniques.</span></p></li><li><p><span>An additional &quot;missing&quot; category can be created if it is informative for the classification or regression task.</span></p></li></ol><h4 id='what-is-overfitting-in-the-context-of-decision-trees-and-how-can-it-be-addressed'><span>What is overfitting in the context of Decision Trees, and how can it be addressed?</span></h4><p><span>Overfitting occurs when a Decision Tree captures noise or irrelevant patterns from the training data, leading to poor generalization on unseen data. Signs of overfitting include overly complex trees with many branches and low accuracy on test data.</span></p><p><span>To address overfitting in Decision Trees:</span></p><ol><li><p><span>Pruning techniques can be applied to reduce the size and complexity of the tree, such as cost complexity pruning or reduced error pruning.</span></p></li><li><p><span>Setting a maximum depth or minimum number of samples per leaf can limit the tree&#39;s growth.</span></p></li><li><p><span>Increasing the minimum number of samples required for splitting can prevent overfitting on small subsets.</span></p></li><li><p><span>Cross-validation can be used to evaluate different models and select the one with the best performance on unseen data.</span></p></li></ol><h4 id='what-is-pruning-and-why-is-it-important-in-decision-trees'><span>What is pruning, and why is it important in Decision Trees?</span></h4><p><span>Pruning is the process of reducing the size or complexity of a Decision Tree by removing specific branches or nodes. It is performed after the initial tree is constructed. Pruning is important because it helps prevent overfitting, improves the generalization ability of the tree, and enhances its interpretability.</span></p><p><span>By pruning, we can simplify the tree structure and remove branches that do not contribute significantly to the overall accuracy or predictive power of the model. Pruning aims to strike a balance between model complexity and performance on unseen data, ensuring that the tree captures essential patterns and avoids memorizing noise or outliers in the training data.</span></p><h4 id='what-are-the-different-measures-used-to-assess-the-quality-of-splits-in-decision-trees'><span>What are the different measures used to assess the quality of splits in Decision Trees?</span></h4><p><span>The commonly used measures to assess the quality of splits in Decision Trees are:</span></p><ol><li><p><span>Gini impurity: It measures the probability of incorrectly classifying a randomly chosen element if it were randomly labeled according to the distribution of classes in the subset. Lower Gini impurity indicates a more pure split.</span></p></li><li><p><span>Information gain: It calculates the reduction in entropy (uncertainty) achieved by splitting the data based on a particular feature. Higher information gain indicates a more informative split.</span></p></li><li><p><span>Gain ratio: It is a modification of information gain that takes into account the intrinsic information of each feature. It considers the number of categories or levels in a categorical feature to address bias towards features with many levels.</span></p></li></ol><p><span>These measures help the Decision Tree algorithm determine the optimal split at each node by selecting the feature that maximizes the purity or information gain in the resulting subsets.</span></p><h4 id='how-do-you-handle-categorical-variables-in-a-decision-tree-algorithm'><span>How do you handle categorical variables in a Decision Tree algorithm?</span></h4><p><span>To handle categorical variables in a Decision Tree algorithm:</span></p><ol><li><p><span>One-Hot Encoding: Each category of a categorical variable is transformed into a binary column. For each instance, the column corresponding to its category is set to 1, while the rest are set to 0.</span></p></li><li><p><span>Label Encoding: Assign a unique numerical value to each category. The categorical variable is replaced with these numerical labels. However, this method should be used with caution, as it may introduce a false sense of order or magnitude in the data.</span></p></li></ol><p><span>The choice between these encoding techniques depends on the nature of the categorical variable and the specific requirements of the problem at hand.</span></p><h4 id='how-can-you-handle-continuous-or-numerical-variables-in-decision-trees'><span>How can you handle continuous or numerical variables in Decision Trees?</span></h4><p><span>Decision Trees can handle continuous or numerical variables naturally. They determine the split points based on the values of the numerical variable. Here&#39;s how it works:</span></p><ol><li><p><span>The Decision Tree algorithm searches for the best split point by evaluating different thresholds or ranges based on the numerical variable&#39;s values.</span></p></li><li><p><span>The split point is chosen based on a criterion such as Gini impurity or information gain, aiming to minimize impurity or maximize information gain in the resulting subsets.</span></p></li><li><p><span>Once the split point is determined, the tree branches into two child nodes based on whether the numerical variable&#39;s value is above or below the split point.</span></p></li><li><p><span>The process continues recursively on each branch until a stopping criterion is met (e.g., reaching a maximum depth or minimum number of samples per leaf).</span></p></li></ol><h4 id='what-are-some-methods-for-dealing-with-imbalanced-datasets-when-using-decision-trees'><span>What are some methods for dealing with imbalanced datasets when using Decision Trees?</span></h4><p><span>When dealing with imbalanced datasets in Decision Trees, some methods to consider are:</span></p><ol><li><p><span>Class weights: Assign different weights to the classes during the training process to give more importance to the minority class. This helps balance the impact of different classes on the tree construction.</span></p></li><li><p><span>Sampling techniques: Use techniques like undersampling the majority class or oversampling the minority class to create a more balanced dataset. This can be done by randomly selecting instances or generating synthetic samples.</span></p></li><li><p><span>Ensemble methods: Utilize ensemble methods like Random Forests or Gradient Boosting, which inherently handle imbalanced datasets by combining multiple decision trees.</span></p></li><li><p><span>Cost-sensitive learning: Assign different misclassification costs to different classes. This encourages the algorithm to focus more on correctly classifying instances from the minority class.</span></p></li></ol><p><span>The choice of method depends on the specifics of the dataset and the problem at hand. It&#39;s often recommended to try multiple techniques and evaluate their performance.</span></p><h4 id='can-you-explain-the-concept-of-feature-importance-in-decision-trees'><span>Can you explain the concept of feature importance in Decision Trees?</span></h4><p><span>Feature importance in Decision Trees refers to the measurement of the relative importance or relevance of each feature in the tree&#39;s decision-making process. It helps identify which features have the most significant impact on the target variable.</span></p><p><span>In Decision Trees, feature importance can be determined by considering how much each feature contributes to reducing impurity or improving the information gain at each split. Features that result in significant impurity reduction or information gain are considered more important.</span></p><p><span>The feature importance is calculated based on the number of instances or samples affected by the feature, the depth at which it appears in the tree, and the impurity reduction or information gain associated with its use in splits.</span></p><p><span>Feature importance can provide insights into the underlying patterns and relationships within the data, aiding in feature selection, understanding the predictive power of different features, and generating meaningful insights from the model.</span></p><h4 id='what-are-ensemble-methods-and-how-can-they-be-combined-with-decision-trees'><span>What are ensemble methods, and how can they be combined with Decision Trees?</span></h4><p><span>Ensemble methods combine multiple individual models to create a more robust and accurate predictive model. In the context of Decision Trees, two popular ensemble methods are Random Forests and Gradient Boosting.</span></p><ol><li><p><span>Random Forests: It combines a set of Decision Trees, each trained on a random subset of the data and a random subset of features. The final prediction is determined by aggregating the predictions of all trees, either by majority voting in classification tasks or averaging in regression tasks. Random Forests reduce overfitting, increase stability, and provide feature importance rankings.</span></p></li><li><p><span>Gradient Boosting: It builds an ensemble of Decision Trees sequentially, where each subsequent tree corrects the errors made by the previous trees. The trees are added in a gradient descent manner, minimizing a loss function. Gradient Boosting achieves high predictive accuracy and handles complex relationships in the data. Examples include XGBoost, LightGBM, and AdaBoost.</span></p></li></ol><p><span>These ensemble methods improve the performance of Decision Trees by reducing bias, capturing diverse patterns in the data, and handling high-dimensional and complex problems.</span></p><h4 id='what-is-the-difference-between-random-forests-and-gradient-boosting-algorithms'><span>What is the difference between Random Forests and Gradient Boosting algorithms?</span></h4><p><span>The main differences between Random Forests and Gradient Boosting algorithms are:</span></p><ol><li><p><span>Training Process: Random Forests train each tree independently using random subsets of the data and features, while Gradient Boosting builds trees sequentially, with each tree correcting the errors of the previous trees.</span></p></li><li><p><span>Sample and Feature Selection: Random Forests use bootstrap aggregating (bagging) to randomly select subsets of both samples and features at each tree construction. Gradient Boosting focuses on the samples, assigning different weights to each instance based on the errors made by the previous trees.</span></p></li><li><p><span>Voting Strategy: Random Forests combine predictions by majority voting (for classification) or averaging (for regression) the predictions from multiple trees. Gradient Boosting combines predictions by adding the outputs of the individual trees, sequentially minimizing a loss function.</span></p></li><li><p><span>Bias-Variance Tradeoff: Random Forests reduce variance by averaging multiple independent trees but may have higher bias. Gradient Boosting reduces bias by iteratively correcting errors but may have higher variance.</span></p></li><li><p><span>Feature Importance: Random Forests provide feature importance rankings based on the average impurity reduction across all trees. Gradient Boosting can also provide feature importance, typically based on the number of times a feature is selected for splitting.</span></p></li></ol><p><span>Both algorithms are powerful ensemble methods that improve the performance of Decision Trees, but they have different underlying principles and training approaches.</span></p><h4 id='how-do-you-determine-the-optimal-depth-or-size-of-a-decision-tree'><span>How do you determine the optimal depth or size of a Decision Tree?</span></h4><p><span>Determining the optimal depth or size of a Decision Tree involves finding the right balance between model complexity and generalization ability. Here are some approaches to determine the optimal depth or size:</span></p><ol><li><p><span>Maximum Depth: Set a maximum depth for the Decision Tree. This limits the number of levels or splits in the tree. A deeper tree can capture more complex relationships in the data but increases the risk of overfitting. Cross-validation or validation curves can be used to evaluate different depths and choose the one that maximizes performance on unseen data.</span></p></li><li><p><span>Minimum Number of Samples per Leaf: Specify a minimum number of samples required to create a leaf node. This prevents further splitting if the number of samples at a node is below the threshold. Setting a higher threshold can help prevent overfitting and create simpler trees.</span></p></li><li><p><span>Stopping Criteria: Define other stopping criteria such as minimum information gain, maximum number of leaf nodes, or maximum number of features. These criteria can help control the growth of the tree and prevent overfitting.</span></p></li></ol><p><span>The optimal depth or size of the Decision Tree should be determined by evaluating the model&#39;s performance on a validation set or using cross-validation techniques.</span></p><h4 id='can-you-explain-the-concept-of-information-gain-or-impurity-reduction-in-decision-trees'><span>Can you explain the concept of information gain or impurity reduction in Decision Trees?</span></h4><p><span>Information gain and impurity reduction are concepts used in Decision Trees to determine the quality of a split based on a specific feature. They assess how well a feature separates the data into homogeneous subsets in terms of the target variable.</span></p><p><span>In classification tasks, the impurity or disorder of a set of instances is measured using metrics like Gini impurity or entropy. A node with low impurity means it contains instances predominantly belonging to a single class.</span></p><p><span>Information gain calculates the reduction in impurity achieved by splitting the data based on a particular feature. It measures how much information about the target variable is gained by including that feature in the split. Higher information gain indicates that the feature contributes more to the separation of classes or the prediction task.</span></p><p><span>Impurity reduction is the difference between the impurity of the current node and the weighted average impurity of the resulting child nodes after the split. The feature that results in the highest information gain or impurity reduction is selected as the best feature to split at each internal node of the Decision Tree.</span></p><h4 id='how-do-you-evaluate-the-performance-of-a-decision-tree-model'><span>How do you evaluate the performance of a Decision Tree model?</span></h4><p><span>The performance of a Decision Tree model can be evaluated using various metrics, depending on the task at hand (classification or regression). Here are some commonly used evaluation metrics:</span></p><ol><li><p><span>Classification:</span></p><ul><li><p><span>Accuracy: The proportion of correctly classified instances.</span></p></li><li><p><span>Precision: The ability to correctly identify positive instances.</span></p></li><li><p><span>Recall: The ability to correctly identify all positive instances.</span></p></li><li><p><span>F1 score: The harmonic mean of precision and recall.</span></p></li><li><p><span>Area Under the ROC Curve (AUC-ROC): Measures the model&#39;s ability to discriminate between classes.</span></p></li></ul></li><li><p><span>Regression:</span></p><ul><li><p><span>Mean Absolute Error (MAE): The average absolute difference between predicted and actual values.</span></p></li><li><p><span>Mean Squared Error (MSE): The average squared difference between predicted and actual values.</span></p></li><li><p><span>R-squared: Measures the proportion of variance in the target variable explained by the model.</span></p></li></ul></li></ol><p><span>To evaluate the performance, you can split the dataset into training and testing sets, or use techniques like cross-validation to obtain more reliable estimates of the model&#39;s performance. By comparing the model&#39;s predictions to the true values, you can assess its accuracy and generalization ability.</span></p><h4 id='can-decision-trees-handle-multi-class-classification-problems'><span>Can Decision Trees handle multi-class classification problems?</span></h4><p><span>Yes, Decision Trees can handle multi-class classification problems. Decision Trees are inherently capable of handling both binary and multi-class classification tasks. At each internal node, the tree splits the data based on a feature, and at each leaf node, the majority class or the class with the highest frequency is assigned.</span></p><p><span>During training, the Decision Tree algorithm can handle multiple classes by using appropriate splitting criteria (e.g., Gini impurity or information gain) to find the most informative splits that separate the classes effectively.</span></p><h4 id='how-do-you-interpret-the-rules-generated-by-a-decision-tree-model'><span>How do you interpret the rules generated by a Decision Tree model?</span></h4><p><span>The rules generated by a Decision Tree model can be interpreted by following the path from the root to a specific leaf node. Each node represents a condition or rule based on a feature, and the tree branches based on the outcomes of the conditions.</span></p><p><span>To interpret the rules, you can examine the feature conditions at each node and understand the decisions made by the tree. The rules can provide insights into the relationships between the features and the target variable. The depth and complexity of the tree can affect the interpretability, with simpler trees being easier to interpret.</span></p><p><span>For example, in a binary classification problem, a rule could be interpreted as &quot;If feature A &gt; 5 and feature B &lt; 10, then predict class 1.&quot; By examining the rules, you can gain understanding about the decision-making process of the model and identify the important features that contribute to the predictions.</span></p><h4 id='can-decision-trees-handle-missing-values-and-outliers-during-the-prediction-phase'><span>Can Decision Trees handle missing values and outliers during the prediction phase?</span></h4><p><span>Decision Trees can handle missing values during the prediction phase. When encountering a missing value for a feature at a particular node, the tree can follow different branches based on the available features. The missing value is treated as a separate category or branch in the tree.</span></p><p><span>As for outliers, Decision Trees are relatively robust to outliers because they partition the feature space into regions based on splits, and outliers are likely to be isolated in their own leaf nodes. However, outliers can influence the tree&#39;s structure and decisions if they significantly affect the impurity or information gain.</span></p><h4 id='how-can-decision-trees-be-used-for-feature-selection-or-variable-importance-ranking'><span>How can Decision Trees be used for feature selection or variable importance ranking?</span></h4><p><span>Decision Trees can be used for feature selection or variable importance ranking based on their inherent ability to assess feature importance during the tree construction process. The importance of a feature can be measured using different criteria such as:</span></p><ol><li><p><span>Mean Decrease Impurity: It calculates the total impurity reduction achieved by a feature over all splits in the tree. Features with higher impurity reduction are considered more important.</span></p></li><li><p><span>Mean Decrease Accuracy: It measures the drop in accuracy when a feature is randomly permuted, indicating the importance of the feature in maintaining the model&#39;s accuracy. Features with higher accuracy drop are considered more important.</span></p></li></ol><p><span>Once the Decision Tree model is trained, the feature importance scores can be obtained. The importance scores can be normalized to ensure they sum up to 1 or scaled to a specific range for better interpretation.</span></p><p><span>Based on the feature importance scores, you can perform feature selection by choosing the top-ranked features. This helps in reducing the dimensionality of the data and selecting the most informative features for the predictive task.</span></p><p><span>Additionally, feature importance ranking can provide insights into the underlying relationships between features and the target variable. It helps in understanding which features have a significant impact on the predictions made by the model. This information can be valuable for further analysis, feature engineering, or model explanation.</span></p><h3 id='python-application'><span>Python Application</span></h3><h4 id='using-sklearn'><span>Using Sklearn</span></h4><pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" spellcheck="false" lang="python" style="break-inside: unset;"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 11.0759px; left: 42px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 38px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><span><span>​</span>x</span><div class="CodeMirror-linenumber CodeMirror-gutter-elt"><div>25</div></div></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div style="position: relative;" class="CodeMirror-activeline"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: -38px; width: 38px;"></div><div class="CodeMirror-gutter-wrapper CodeMirror-activeline-gutter" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 29px;">1</div></div><pre class=" CodeMirror-line " role="presentation" style=""><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Import necessary libraries</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">2</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">datasets</span> <span class="cm-keyword">import</span> <span class="cm-variable">load_iris</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">3</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">model_selection</span> <span class="cm-keyword">import</span> <span class="cm-variable">train_test_split</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">4</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">tree</span> <span class="cm-keyword">import</span> <span class="cm-variable">DecisionTreeClassifier</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">5</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">metrics</span> <span class="cm-keyword">import</span> <span class="cm-variable">accuracy_score</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">6</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">7</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Load the IRIS dataset</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">8</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">iris</span> <span class="cm-operator">=</span> <span class="cm-variable">load_iris</span>()</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">9</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 29px;">10</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Split the dataset into training and testing sets</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">11</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">X_train</span>, <span class="cm-variable">X_test</span>, <span class="cm-variable">y_train</span>, <span class="cm-variable">y_test</span> <span class="cm-operator">=</span> <span class="cm-variable">train_test_split</span>(<span class="cm-variable">iris</span>.<span class="cm-property">data</span>, <span class="cm-variable">iris</span>.<span class="cm-property">target</span>, <span class="cm-variable">test_size</span><span class="cm-operator">=</span><span class="cm-number">0.2</span>, <span class="cm-variable">random_state</span><span class="cm-operator">=</span><span class="cm-number">42</span>)</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">12</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">13</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Create a Decision Tree classifier</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">14</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">clf</span> <span class="cm-operator">=</span> <span class="cm-variable">DecisionTreeClassifier</span>()</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">15</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">16</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Train the classifier on the training data</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">17</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">clf</span>.<span class="cm-property">fit</span>(<span class="cm-variable">X_train</span>, <span class="cm-variable">y_train</span>)</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">18</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">19</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Make predictions on the testing data</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 29px;">20</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">y_pred</span> <span class="cm-operator">=</span> <span class="cm-variable">clf</span>.<span class="cm-property">predict</span>(<span class="cm-variable">X_test</span>)</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">21</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">22</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Evaluate the accuracy of the classifier</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">23</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">accuracy</span> <span class="cm-operator">=</span> <span class="cm-variable">accuracy_score</span>(<span class="cm-variable">y_test</span>, <span class="cm-variable">y_pred</span>)</span></pre></div><div class="" style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 29px;">24</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">"Accuracy:"</span>, <span class="cm-variable">accuracy</span>)</span></pre></div></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 654px;"></div><div class="CodeMirror-gutters" style="height: 654px;"><div class="CodeMirror-gutter CodeMirror-linenumbers" style="width: 37px;"></div></div></div></div></pre><p><span>In this code snippet, we first import the necessary libraries: </span><code>load_iris</code><span> from </span><code>sklearn.datasets</code><span> to load the IRIS dataset, </span><code>train_test_split</code><span> from </span><code>sklearn.model_selection</code><span> to split the dataset into training and testing sets, </span><code>DecisionTreeClassifier</code><span> from </span><code>sklearn.tree</code><span> to create a Decision Tree classifier, and </span><code>accuracy_score</code><span> from </span><code>sklearn.metrics</code><span> to evaluate the accuracy of the classifier.</span></p><p><span>Next, we load the IRIS dataset and split it into training and testing sets using the </span><code>train_test_split</code><span> function. Then, we create an instance of the Decision Tree classifier and train it on the training data using the </span><code>fit</code><span> method.</span></p><p><span>After training, we use the trained classifier to make predictions on the testing data with the </span><code>predict</code><span> method. Finally, we evaluate the accuracy of the predictions by comparing them to the true labels and print the accuracy score.</span></p><p><span>Make sure to have scikit-learn installed (</span><code>pip install scikit-learn</code><span>) before running the code.</span></p><h5 id='decisiontreeclassifier'><code>DecisionTreeClassifier()</code></h5><p><code>DecisionTreeClassifier</code><span> is a class in scikit-learn that implements the Decision Tree algorithm for classification tasks. It is a versatile and widely used machine learning algorithm known for its simplicity and interpretability.</span></p><p><span>Here is a detailed explanation of the </span><code>DecisionTreeClassifier</code><span> class and its important parameters:</span></p><pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" spellcheck="false" lang="python"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 11.0759px; left: 32px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 28px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre><div class="CodeMirror-linenumber CodeMirror-gutter-elt"><div>1</div></div></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div style="position: relative;" class="CodeMirror-activeline"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: -28px; width: 28px;"></div><div class="CodeMirror-gutter-wrapper CodeMirror-activeline-gutter" style="left: -28px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 19px;">1</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">DecisionTreeClassifier</span>(<span class="cm-variable">criterion</span><span class="cm-operator">=</span><span class="cm-string">'gini'</span>, <span class="cm-variable">splitter</span><span class="cm-operator">=</span><span class="cm-string">'best'</span>, <span class="cm-variable">max_depth</span><span class="cm-operator">=</span><span class="cm-keyword">None</span>, </span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -28px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 19px;">2</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="cm-variable">min_samples_split</span><span class="cm-operator">=</span><span class="cm-number">2</span>, <span class="cm-variable">min_samples_leaf</span><span class="cm-operator">=</span><span class="cm-number">1</span>, </span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -28px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 19px;">3</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="cm-variable">min_weight_fraction_leaf</span><span class="cm-operator">=</span><span class="cm-number">0.0</span>, <span class="cm-variable">max_features</span><span class="cm-operator">=</span><span class="cm-keyword">None</span>, </span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -28px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 19px;">4</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="cm-variable">random_state</span><span class="cm-operator">=</span><span class="cm-keyword">None</span>, <span class="cm-variable">max_leaf_nodes</span><span class="cm-operator">=</span><span class="cm-keyword">None</span>, </span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -28px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 19px;">5</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="cm-variable">min_impurity_decrease</span><span class="cm-operator">=</span><span class="cm-number">0.0</span>, <span class="cm-variable">min_impurity_split</span><span class="cm-operator">=</span><span class="cm-keyword">None</span>, </span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -28px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 19px;">6</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="cm-variable">class_weight</span><span class="cm-operator">=</span><span class="cm-keyword">None</span>, <span class="cm-variable">presort</span><span class="cm-operator">=</span><span class="cm-string">'deprecated'</span>, <span class="cm-variable">ccp_alpha</span><span class="cm-operator">=</span><span class="cm-number">0.0</span>)</span></pre></div><div class="" style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -28px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 19px;">7</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 183px;"></div><div class="CodeMirror-gutters" style="height: 183px;"><div class="CodeMirror-gutter CodeMirror-linenumbers" style="width: 27px;"></div></div></div></div></pre><ul><li><p><code>criterion</code><span> (default: &#39;gini&#39;): The function to measure the quality of a split. It can be either &#39;gini&#39; for the Gini impurity or &#39;entropy&#39; for information gain. Gini impurity is the default as it tends to be faster and is commonly used.</span></p></li><li><p><code>splitter</code><span> (default: &#39;best&#39;): The strategy used to choose the split at each node. It can be either &#39;best&#39; to choose the best split based on the criterion or &#39;random&#39; to choose the best random split.</span></p></li><li><p><code>max_depth</code><span> (default: None): The maximum depth of the tree. If None, the tree is grown until all leaves are pure or until all leaves contain less than </span><code>min_samples_split</code><span> samples.</span></p></li><li><p><code>min_samples_split</code><span> (default: 2): The minimum number of samples required to split an internal node. A split is not allowed if the number of samples at a node is less than this value.</span></p></li><li><p><code>min_samples_leaf</code><span> (default: 1): The minimum number of samples required to be at a leaf node. A split is not allowed if it would result in a leaf node with fewer samples than this value.</span></p></li><li><p><code>min_weight_fraction_leaf</code><span> (default: 0.0): The minimum weighted fraction of the sum total of weights required to be at a leaf node.</span></p></li><li><p><code>max_features</code><span> (default: None): The number of features to consider when looking for the best split. If None, all features are considered. It can be an integer (the number of features) or a fraction (a percentage of features).</span></p></li><li><p><code>random_state</code><span> (default: None): The seed of the random number generator used to select a random feature to consider at each split. It ensures reproducibility of the results.</span></p></li><li><p><code>max_leaf_nodes</code><span> (default: None): The maximum number of leaf nodes in the tree. If None, unlimited leaf nodes are allowed.</span></p></li><li><p><code>min_impurity_decrease</code><span> (default: 0.0): A node will be split if this split induces a decrease of the impurity greater than or equal to this value.</span></p></li><li><p><code>min_impurity_split</code><span> (default: None): This parameter is deprecated and will be removed in future versions.</span></p></li><li><p><code>class_weight</code><span> (default: None): Weights associated with classes. It can be a dictionary of the form </span><code>{class_label: weight}</code><span> or &#39;balanced&#39; to automatically adjust weights based on the class frequencies.</span></p></li><li><p><code>presort</code><span> (default: &#39;deprecated&#39;): This parameter is deprecated and will be removed in future versions.</span></p></li><li><p><code>ccp_alpha</code><span> (default: 0.0): Complexity parameter used for Minimal Cost-Complexity Pruning. It limits the size of the tree by controlling the trade-off between complexity and accuracy.</span></p></li></ul><h4 id='from-scratch'><span>From Scratch</span></h4><pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" spellcheck="false" lang="python" style="break-inside: unset;"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 11.0759px; left: 42px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 38px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div style="position: relative;" class="CodeMirror-activeline"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: -38px; width: 38px;"></div><div class="CodeMirror-gutter-wrapper CodeMirror-activeline-gutter" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 29px;">1</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">class</span> <span class="cm-def">DecisionTree</span>:</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">2</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-keyword">def</span> <span class="cm-def">__init__</span>(<span class="cm-variable-2">self</span>):</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">3</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable-2">self</span>.<span class="cm-property">tree</span> <span class="cm-operator">=</span> <span class="cm-keyword">None</span> &nbsp;<span class="cm-comment"># 存储决策树的根节点</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">4</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">5</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-keyword">def</span> <span class="cm-def">fit</span>(<span class="cm-variable-2">self</span>, <span class="cm-variable">X</span>, <span class="cm-variable">y</span>):</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">6</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable-2">self</span>.<span class="cm-property">tree</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">_grow_tree</span>(<span class="cm-variable">X</span>, <span class="cm-variable">y</span>) &nbsp;<span class="cm-comment"># 训练决策树</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">7</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">8</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-keyword">def</span> <span class="cm-def">_grow_tree</span>(<span class="cm-variable-2">self</span>, <span class="cm-variable">X</span>, <span class="cm-variable">y</span>):</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">9</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">if</span> <span class="cm-builtin">len</span>(<span class="cm-variable">np</span>.<span class="cm-property">unique</span>(<span class="cm-variable">y</span>)) <span class="cm-operator">==</span> <span class="cm-number">1</span>: &nbsp;<span class="cm-comment"># 如果所有样本属于同一类别，创建叶节点并返回该类别</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 29px;">10</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">return</span> <span class="cm-variable">np</span>.<span class="cm-property">unique</span>(<span class="cm-variable">y</span>)[<span class="cm-number">0</span>]</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">11</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">12</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">feature_index</span>, <span class="cm-variable">threshold</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">_find_best_split</span>(<span class="cm-variable">X</span>, <span class="cm-variable">y</span>) &nbsp;<span class="cm-comment"># 找到最佳的分割特征和阈值</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">13</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">if</span> <span class="cm-variable">feature_index</span> <span class="cm-keyword">is</span> <span class="cm-keyword">None</span> <span class="cm-keyword">or</span> <span class="cm-variable">threshold</span> <span class="cm-keyword">is</span> <span class="cm-keyword">None</span>: &nbsp;<span class="cm-comment"># 如果无法找到最佳分割点，创建叶节点并返回样本中最多的类别</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">14</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">return</span> <span class="cm-variable">np</span>.<span class="cm-property">bincount</span>(<span class="cm-variable">y</span>).<span class="cm-property">argmax</span>()</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">15</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">16</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">left_indices</span> <span class="cm-operator">=</span> <span class="cm-variable">X</span>[:, <span class="cm-variable">feature_index</span>] <span class="cm-operator">&lt;=</span> <span class="cm-variable">threshold</span> &nbsp;<span class="cm-comment"># 根据最佳分割点将数据集划分为左子集和右子集</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">17</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">right_indices</span> <span class="cm-operator">=</span> <span class="cm-variable">X</span>[:, <span class="cm-variable">feature_index</span>] <span class="cm-operator">&gt;</span> <span class="cm-variable">threshold</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">18</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">X_left</span>, <span class="cm-variable">y_left</span> <span class="cm-operator">=</span> <span class="cm-variable">X</span>[<span class="cm-variable">left_indices</span>], <span class="cm-variable">y</span>[<span class="cm-variable">left_indices</span>] &nbsp;<span class="cm-comment"># 左子集的特征和标签</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">19</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">X_right</span>, <span class="cm-variable">y_right</span> <span class="cm-operator">=</span> <span class="cm-variable">X</span>[<span class="cm-variable">right_indices</span>], <span class="cm-variable">y</span>[<span class="cm-variable">right_indices</span>] &nbsp;<span class="cm-comment"># 右子集的特征和标签</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 29px;">20</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">21</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">left_subtree</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">_grow_tree</span>(<span class="cm-variable">X_left</span>, <span class="cm-variable">y_left</span>) &nbsp;<span class="cm-comment"># 递归构建左子树</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">22</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">right_subtree</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">_grow_tree</span>(<span class="cm-variable">X_right</span>, <span class="cm-variable">y_right</span>) &nbsp;<span class="cm-comment"># 递归构建右子树</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">23</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">24</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">return</span> (<span class="cm-variable">feature_index</span>, <span class="cm-variable">threshold</span>, <span class="cm-variable">left_subtree</span>, <span class="cm-variable">right_subtree</span>) &nbsp;<span class="cm-comment"># 返回当前节点的分割特征、阈值以及左右子树的引用</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">25</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">26</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-keyword">def</span> <span class="cm-def">_find_best_split</span>(<span class="cm-variable-2">self</span>, <span class="cm-variable">X</span>, <span class="cm-variable">y</span>):</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">27</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">best_gain</span> <span class="cm-operator">=</span> <span class="cm-number">0</span> &nbsp;<span class="cm-comment"># 用于记录最佳信息增益</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">28</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">best_feature_index</span> <span class="cm-operator">=</span> <span class="cm-keyword">None</span> &nbsp;<span class="cm-comment"># 用于记录最佳分割特征的索引</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">29</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">best_threshold</span> <span class="cm-operator">=</span> <span class="cm-keyword">None</span> &nbsp;<span class="cm-comment"># 用于记录最佳分割阈值</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 29px;">30</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">31</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">n_features</span> <span class="cm-operator">=</span> <span class="cm-variable">X</span>.<span class="cm-property">shape</span>[<span class="cm-number">1</span>] &nbsp;<span class="cm-comment"># 特征的数量</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">32</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">for</span> <span class="cm-variable">feature_index</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-variable">n_features</span>): &nbsp;<span class="cm-comment"># 遍历所有特征</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">33</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">unique_values</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">unique</span>(<span class="cm-variable">X</span>[:, <span class="cm-variable">feature_index</span>]) &nbsp;<span class="cm-comment"># 当前特征的唯一值</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">34</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">thresholds</span> <span class="cm-operator">=</span> (<span class="cm-variable">unique_values</span>[:<span class="cm-operator">-</span><span class="cm-number">1</span>] <span class="cm-operator">+</span> <span class="cm-variable">unique_values</span>[<span class="cm-number">1</span>:]) <span class="cm-operator">/</span> <span class="cm-number">2</span> &nbsp;<span class="cm-comment"># 计算所有可能的分割阈值</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">35</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">36</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">for</span> <span class="cm-variable">threshold</span> <span class="cm-keyword">in</span> <span class="cm-variable">thresholds</span>: &nbsp;<span class="cm-comment"># 遍历所有分割阈值</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">37</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">left_indices</span> <span class="cm-operator">=</span> <span class="cm-variable">X</span>[:, <span class="cm-variable">feature_index</span>] <span class="cm-operator">&lt;=</span> <span class="cm-variable">threshold</span> &nbsp;<span class="cm-comment"># 根据分割阈值划分数据集</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">38</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">right_indices</span> <span class="cm-operator">=</span> <span class="cm-variable">X</span>[:, <span class="cm-variable">feature_index</span>] <span class="cm-operator">&gt;</span> <span class="cm-variable">threshold</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">39</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 29px;">40</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">left_entropy</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">_calculate_entropy</span>(<span class="cm-variable">y</span>[<span class="cm-variable">left_indices</span>]) &nbsp;<span class="cm-comment"># 计算左子集的熵</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">41</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">right_entropy</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">_calculate_entropy</span>(<span class="cm-variable">y</span>[<span class="cm-variable">right_indices</span>]) &nbsp;<span class="cm-comment"># 计算右子集的熵</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">42</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">weighted_avg_entropy</span> <span class="cm-operator">=</span> (<span class="cm-variable">left_entropy</span> <span class="cm-operator">*</span> <span class="cm-builtin">len</span>(<span class="cm-variable">left_indices</span>) <span class="cm-operator">+</span> <span class="cm-variable">right_entropy</span> <span class="cm-operator">*</span> <span class="cm-builtin">len</span>(<span class="cm-variable">right_indices</span>)) <span class="cm-operator">/</span> <span class="cm-builtin">len</span>(<span class="cm-variable">y</span>) &nbsp;<span class="cm-comment"># 计算加权平均熵</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">43</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">44</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">information_gain</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">_information_gain</span> <span class="cm-operator">=</span> <span class="cm-variable-2">self</span>.<span class="cm-property">_calculate_entropy</span>(<span class="cm-variable">y</span>) <span class="cm-operator">-</span> <span class="cm-variable">weighted_avg_entropy</span> &nbsp;<span class="cm-comment"># 计算信息增益</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">45</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">46</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">if</span> <span class="cm-variable">information_gain</span> <span class="cm-operator">&gt;</span> <span class="cm-variable">best_gain</span>: &nbsp;<span class="cm-comment"># 如果当前信息增益大于最佳信息增益，则更新最佳信息增益和相应的分割特征及阈值</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">47</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">best_gain</span> <span class="cm-operator">=</span> <span class="cm-variable">information_gain</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">48</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">best_feature_index</span> <span class="cm-operator">=</span> <span class="cm-variable">feature_index</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">49</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">best_threshold</span> <span class="cm-operator">=</span> <span class="cm-variable">threshold</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 29px;">50</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">51</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">return</span> <span class="cm-variable">best_feature_index</span>, <span class="cm-variable">best_threshold</span> &nbsp;<span class="cm-comment"># 返回最佳分割特征和阈值</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">52</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">53</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-keyword">def</span> <span class="cm-def">_calculate_entropy</span>(<span class="cm-variable-2">self</span>, <span class="cm-variable">y</span>):</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">54</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">unique_classes</span>, <span class="cm-variable">class_counts</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">unique</span>(<span class="cm-variable">y</span>, <span class="cm-variable">return_counts</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>) &nbsp;<span class="cm-comment"># 统计每个类别的数量</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">55</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">probabilities</span> <span class="cm-operator">=</span> <span class="cm-variable">class_counts</span> <span class="cm-operator">/</span> <span class="cm-builtin">len</span>(<span class="cm-variable">y</span>) &nbsp;<span class="cm-comment"># 计算每个类别的概率</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">56</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">entropy</span> <span class="cm-operator">=</span> <span class="cm-operator">-</span><span class="cm-variable">np</span>.<span class="cm-property">sum</span>(<span class="cm-variable">probabilities</span> <span class="cm-operator">*</span> <span class="cm-variable">np</span>.<span class="cm-property">log2</span>(<span class="cm-variable">probabilities</span> <span class="cm-operator">+</span> <span class="cm-number">1e-10</span>)) &nbsp;<span class="cm-comment"># 计算熵</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">57</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">return</span> <span class="cm-variable">entropy</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">58</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">59</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-keyword">def</span> <span class="cm-def">predict</span>(<span class="cm-variable-2">self</span>, <span class="cm-variable">X</span>):</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 29px;">60</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">return</span> <span class="cm-variable">np</span>.<span class="cm-property">array</span>([<span class="cm-variable-2">self</span>.<span class="cm-property">_traverse_tree</span>(<span class="cm-variable">x</span>, <span class="cm-variable-2">self</span>.<span class="cm-property">tree</span>) <span class="cm-keyword">for</span> <span class="cm-variable">x</span> <span class="cm-keyword">in</span> <span class="cm-variable">X</span>]) &nbsp;<span class="cm-comment"># 对测试样本进行预测</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">61</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">62</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-keyword">def</span> <span class="cm-def">_traverse_tree</span>(<span class="cm-variable-2">self</span>, <span class="cm-variable">x</span>, <span class="cm-variable">node</span>):</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">63</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">if</span> <span class="cm-builtin">isinstance</span>(<span class="cm-variable">node</span>, <span class="cm-variable">np</span>.<span class="cm-property">int64</span>): &nbsp;<span class="cm-comment"># 如果当前节点是叶节点，直接返回节点的类别</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">64</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">return</span> <span class="cm-variable">node</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">65</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">66</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">feature_index</span>, <span class="cm-variable">threshold</span>, <span class="cm-variable">left_subtree</span>, <span class="cm-variable">right_subtree</span> <span class="cm-operator">=</span> <span class="cm-variable">node</span> &nbsp;<span class="cm-comment"># 获取当前节点的分割特征、阈值以及左右子树</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">67</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">68</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">if</span> <span class="cm-variable">x</span>[<span class="cm-variable">feature_index</span>] <span class="cm-operator">&lt;=</span> <span class="cm-variable">threshold</span>: &nbsp;<span class="cm-comment"># 根据分割特征和阈值决定向左子树还是向右子树遍历</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">69</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">return</span> <span class="cm-variable-2">self</span>.<span class="cm-property">_traverse_tree</span>(<span class="cm-variable">x</span>, <span class="cm-variable">left_subtree</span>)</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 29px;">70</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">else</span>:</span></pre></div><div class="" style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">71</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">return</span> <span class="cm-variable-2">self</span>.<span class="cm-property">_traverse_tree</span>(<span class="cm-variable">x</span>, <span class="cm-variable">right_subtree</span>)</span></pre></div><div class="" style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 29px;">72</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 2040px;"></div><div class="CodeMirror-gutters" style="height: 2040px;"><div class="CodeMirror-gutter CodeMirror-linenumbers" style="width: 37px;"></div></div></div></div></pre><pre class="md-fences md-end-block md-fences-with-lineno ty-contain-cm modeLoaded" spellcheck="false" lang="py" style="break-inside: unset;"><div class="CodeMirror cm-s-inner cm-s-null-scroll CodeMirror-wrap" lang="py"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 11.0759px; left: 42px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 38px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre><div class="CodeMirror-linenumber CodeMirror-gutter-elt"><div>1</div></div><div class="CodeMirror-linenumber CodeMirror-gutter-elt"><div>23</div></div></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div style="position: relative;" class="CodeMirror-activeline"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: -38px; width: 38px;"></div><div class="CodeMirror-gutter-wrapper CodeMirror-activeline-gutter" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 29px;">1</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">numpy</span> <span class="cm-keyword">as</span> <span class="cm-variable">np</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">2</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">datasets</span> <span class="cm-keyword">import</span> <span class="cm-variable">load_iris</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">3</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">model_selection</span> <span class="cm-keyword">import</span> <span class="cm-variable">train_test_split</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">4</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">5</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Load the IRIS dataset</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">6</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">iris</span> <span class="cm-operator">=</span> <span class="cm-variable">load_iris</span>()</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">7</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">X</span>, <span class="cm-variable">y</span> <span class="cm-operator">=</span> <span class="cm-variable">iris</span>.<span class="cm-property">data</span>, <span class="cm-variable">iris</span>.<span class="cm-property">target</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">8</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">9</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Split the data into training and testing sets</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 29px;">10</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">X_train</span>, <span class="cm-variable">X_test</span>, <span class="cm-variable">y_train</span>, <span class="cm-variable">y_test</span> <span class="cm-operator">=</span> <span class="cm-variable">train_test_split</span>(<span class="cm-variable">X</span>, <span class="cm-variable">y</span>, <span class="cm-variable">test_size</span><span class="cm-operator">=</span><span class="cm-number">0.2</span>, <span class="cm-variable">random_state</span><span class="cm-operator">=</span><span class="cm-number">42</span>)</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">11</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">12</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Create an instance of the DecisionTree classifier</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">13</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">clf</span> <span class="cm-operator">=</span> <span class="cm-variable">DecisionTree</span>()</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">14</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">15</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Fit the classifier to the training data</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">16</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">clf</span>.<span class="cm-property">fit</span>(<span class="cm-variable">X_train</span>, <span class="cm-variable">y_train</span>)</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">17</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">18</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Make predictions on the testing data</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">19</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">y_pred</span> <span class="cm-operator">=</span> <span class="cm-variable">clf</span>.<span class="cm-property">predict</span>(<span class="cm-variable">X_test</span>)</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 29px;">20</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">21</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Evaluate the accuracy of the classifier</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">22</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">accuracy</span> <span class="cm-operator">=</span> <span class="cm-variable">np</span>.<span class="cm-property">mean</span>(<span class="cm-variable">y_pred</span> <span class="cm-operator">==</span> <span class="cm-variable">y_test</span>)</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">23</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">"Accuracy:"</span>, <span class="cm-variable">accuracy</span>)</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">24</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">25</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">sklearn</span>.<span class="cm-property">metrics</span> <span class="cm-keyword">import</span> <span class="cm-variable">confusion_matrix</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">26</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">matplotlib</span>.<span class="cm-property">pyplot</span> <span class="cm-keyword">as</span> <span class="cm-variable">plt</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">27</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">seaborn</span> <span class="cm-keyword">as</span> <span class="cm-variable">sns</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">28</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Compute the confusion matrix</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">29</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">cm</span> <span class="cm-operator">=</span> <span class="cm-variable">confusion_matrix</span>(<span class="cm-variable">y_test</span>, <span class="cm-variable">y_pred</span>)</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 29px;">30</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">31</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Plot the confusion matrix as a heatmap</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">32</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">sns</span>.<span class="cm-property">heatmap</span>(<span class="cm-variable">cm</span>, <span class="cm-variable">annot</span><span class="cm-operator">=</span><span class="cm-keyword">True</span>, <span class="cm-variable">cmap</span><span class="cm-operator">=</span><span class="cm-string">'Blues'</span>, <span class="cm-variable">fmt</span><span class="cm-operator">=</span><span class="cm-string">'d'</span>, <span class="cm-variable">xticklabels</span><span class="cm-operator">=</span><span class="cm-variable">iris</span>.<span class="cm-property">target_names</span>, <span class="cm-variable">yticklabels</span><span class="cm-operator">=</span><span class="cm-variable">iris</span>.<span class="cm-property">target_names</span>)</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">33</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">34</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Add labels and title</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">35</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">xlabel</span>(<span class="cm-string">'Predicted'</span>)</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">36</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">ylabel</span>(<span class="cm-string">'True'</span>)</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">37</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">title</span>(<span class="cm-string">'Confusion Matrix'</span>)</span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">38</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="" cm-zwsp="">
</span></span></pre></div><div style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt" style="left: 0px; width: 29px;">39</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Display the heatmap</span></span></pre></div><div class="" style="position: relative;"><div class="CodeMirror-gutter-wrapper" style="left: -38px;"><div class="CodeMirror-linenumber CodeMirror-gutter-elt CodeMirror-linenumber-show" style="left: 0px; width: 29px;">40</div></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-property">show</span>()</span></pre></div></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 1072px;"></div><div class="CodeMirror-gutters" style="height: 1072px;"><div class="CodeMirror-gutter CodeMirror-linenumbers" style="width: 37px;"></div></div></div></div></pre><p><img src="data:image/png;base64,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" referrerpolicy="no-referrer" alt="img"></p></div></div>
</body>
</html>