---
layout: post
title: Convoluntion Neural Network for Image Identification
subtitle: Develop a CNN for CIFAR-10
cover-img: image/cover14.jpeg
tags: [blogs, insights]
---

## Image Classification in Deep Learning

Image classification refers to a process in computer vision that can classify an image according to its visual content. For example, an image classification algorithm may be designed to tell if an image contains a human figure or not. While detecting an object is trivial for humans, robust image classification is still a challenge in [computer vision applications.](https://www.sciencedirect.com/topics/computer-science/computer-vision-applications)

I have posted some materials in [Digit Recognition in Artificial Neural Network Using TensorFlow 2.0](https://zg104.github.io/2020-05-24-Aritificial-Neural-Network-In-TF-2.0.md/) which contains my insights about how to use ANN for digit recognition. However, MINST dataset seems to be pretty easy for modern machine learning models, since the digit is of pixel (28, 28), which is relatively small. Traditional ANN can handle it quite well. However, there are many more HD prictures which multiple colors that can be hard to classify. So, we have to introduce something new for this.

### Convolutional Neural Network

![](https://ars.els-cdn.com/content/image/1-s2.0-S1568494618302151-gr1.jpg)


<p align="center">
  <img src="https://miro.medium.com/max/1400/1*uAeANQIOQPqWZnnuH-VEyw.jpeg">
</p>

#### What is CNN?

A [__Convolutional Neural Network__](https://en.wikipedia.org/wiki/Convolutional_neural_network)(ConvNet/CNN) is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other. The pre-processing required in a ConvNet is much lower as compared to other classification algorithms. While in primitive methods filters are hand-engineered, with enough training, ConvNets have the ability to learn these filters/characteristics.
The architecture of a ConvNet is analogous to that of the connectivity pattern of Neurons in the Human Brain and was inspired by the organization of the Visual Cortex. Individual neurons respond to stimuli only in a restricted region of the visual field known as the Receptive Field. A collection of such fields overlap to cover the entire visual area.

#### What is Convolution?

By now, we know that a convolutional neural network is just a "neural network with convolution". Never think of convolution as something mysterious! You only need to know how to **add** and **multiply**. 

Basically, convolution is a process for image modifier by using different filters or kernels to extract and transform the features into something the traditional neural network likes.

<p align="center">
  <img src="https://media0.giphy.com/media/i4NjAwytgIRDW/200.webp?cid=ecf05e476cd02eb017feeca333a59ce44bcc3781f646ebd2&rid=200.webp">
</p>

For example, if the input length = N, Kernel length = K, Output length = N - K + 1. Always remember that!

And you can think of convolution as cross-correlation which means there is a degree of similarity between variables. The only difference between correlation and convolution is that convolution reverses the orientation of the filter wheras correlation does not.

#### What is Padding?

Now, I bet you know how convolution works. Basically, you are sliding the filter across every possible position in the input image. The motion of the filter is bounded by the edges of the image. Therefore, the output image is always smaller than the input image.

<p align="center">
  <img src="https://miro.medium.com/max/1920/1*D6iRfzDkz-sEzyjYoVZ73w.gif">
</p>

What if we want the output to be the same size as the input? Then we can use padding (add imaginary zeros around the input). 

<p align="center">
  <img src="https://miro.medium.com/max/790/1*1VJDP6qDY9-ExTuQVEOlVg.gif">
</p>


So, we have 3 modes for padding.

| Mode | Output Size | Usage |
| :-: | :-: | :-:|
| Valid | N-K+1 | Typical |
| Same | N | Typical |
| Full | N+K-1 | Atypical |

The kernel filters out everything not related to the pattern contained in the filter.

#### Alternative Perspectives on Convolution

How to view convolution as matrix multiplication? 

<p align="center">
  <img src = "https://i.stack.imgur.com/y5hMX.png" width = 700 height = 350>
</p>

So, we can do convolution without _actually_ doing convolution by repeating the same filter again and again. But, there is a problem that the matrix multiplication can be pretty big and slow. 

#### Weight Sharing / Weight Sharing

What if, instead of a full weight matrix, we only used the same weights over and over? Then we could have less parameters, use up less RAM, and make the computation more efficient. We don't need each weight for each part of the neural network. Remember that convolution is actually correlation and the filter is really a pattern finder. We want the __same__ filter to look at __all locations__ in the image -- translational invariance. 

If we used a fully-connected neural network for two images like that, the weights would have to learn to find the dog in each possible position and orientation separately. But the dog is still the same dog, right? 

<p align="center">
  <img src = "https://miro.medium.com/max/3200/0*TH5N8CGX5tGKImmT.png">
</p>

#### Convolution on Color Images

We know that images are 3-D objects: Height x Width x Color, but all of the examples of convolution we saw were on 2-D objects.


<p align="center">
  <img src = "https://xrds.acm.org/blog/wp-content/uploads/2016/06/Figure1.png">
</p>

Actually, we can use as many filters as we want to stack or extend the 2-D


